{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe70a96",
   "metadata": {},
   "source": [
    "## Interval Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbda12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize()\n",
       "  (1): Net(\n",
       "    (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorboardX\n",
    "# !pip install bound-propagation\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "## Simple NN. You can change this if you want. If you change it, mention the architectural details in your report.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 200)\n",
    "        self.fc2 = nn.Linear(200,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28*28))\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=-1) # added softmax for probabilities\n",
    "        return x\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307)/0.3081\n",
    "\n",
    "# Add the data normalization as a first \"layer\" to the network\n",
    "# this allows us to search for adverserial examples to the real image, rather than\n",
    "# to the normalized image\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6282f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.3f}')\n",
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy on images: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dd8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 2.012\n",
      "Epoch 2/15, Loss: 1.729\n",
      "Epoch 3/15, Loss: 1.627\n",
      "Epoch 4/15, Loss: 1.596\n",
      "Epoch 5/15, Loss: 1.582\n",
      "Epoch 6/15, Loss: 1.572\n",
      "Epoch 7/15, Loss: 1.566\n",
      "Epoch 8/15, Loss: 1.561\n",
      "Epoch 9/15, Loss: 1.557\n",
      "Epoch 10/15, Loss: 1.553\n",
      "Epoch 11/15, Loss: 1.550\n",
      "Epoch 12/15, Loss: 1.547\n",
      "Epoch 13/15, Loss: 1.545\n",
      "Epoch 14/15, Loss: 1.542\n",
      "Epoch 15/15, Loss: 1.540\n",
      "Accuracy on images: 93.43\n"
     ]
    }
   ],
   "source": [
    "train_model(model, 15)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c23f92",
   "metadata": {},
   "source": [
    "### Write the interval analysis for the simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97f7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Write the interval analysis for the simple model\n",
    "## you can use https://github.com/Zinoex/bound_propagation\n",
    "\n",
    "from bound_propagation import BoundModelFactory, BoundModule, IntervalBounds, HyperRectangle\n",
    "from bound_propagation.sequential import BoundSequential\n",
    "\n",
    "class BoundNet(BoundModule):\n",
    "    def __init__(self, model, factory, **kwargs):\n",
    "        super().__init__(model, factory, **kwargs)\n",
    "        self.fc1 = factory.build(model.fc1)\n",
    "        self.relu = factory.build(nn.ReLU())\n",
    "        self.fc2 = factory.build(model.fc2)\n",
    "        self.softmax = factory.build(nn.Softmax(dim=-1))\n",
    "\n",
    "    def propagate_size(self, in_size):\n",
    "        # We have to flatten the input here to match the first linear layer\n",
    "        size = (in_size[0], 784)\n",
    "        size = self.fc1.propagate_size(size)\n",
    "        size = self.relu.propagate_size(size)\n",
    "        size = self.fc2.propagate_size(size)\n",
    "        size = self.softmax.propagate_size(size)\n",
    "        return size\n",
    "\n",
    "    def ibp_forward(self, bounds, save_relaxation=False, save_input_bounds=False):\n",
    "        # Again have to flatten the bounds to match the first linear layer\n",
    "        lower = bounds.lower.view(bounds.lower.size(0), -1)\n",
    "        upper = bounds.upper.view(bounds.upper.size(0), -1)\n",
    "        bounds = IntervalBounds(bounds.region, lower, upper)\n",
    "\n",
    "        bounds = self.fc1.ibp_forward(bounds, save_relaxation, save_input_bounds)\n",
    "        bounds = self.relu.ibp_forward(bounds, save_relaxation, save_input_bounds)\n",
    "        bounds = self.fc2.ibp_forward(bounds, save_relaxation, save_input_bounds)\n",
    "        bounds = self.softmax.ibp_forward(bounds, save_relaxation, save_input_bounds)\n",
    "        return bounds\n",
    "\n",
    "    @property\n",
    "    def need_relaxation(self):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def clear_relaxation(self):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward_relaxation(self, region):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def crown_backward(self, linear_bounds, optimize):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class BoundNormalize(BoundModule):\n",
    "    def __init__(self, model, factory, **kwargs):\n",
    "        super().__init__(model, factory, **kwargs)\n",
    "        self.mean = torch.tensor([0.1307], device=device)\n",
    "        self.std = torch.tensor([0.3081], device=device)\n",
    "\n",
    "    def propagate_size(self, in_size):\n",
    "        return in_size\n",
    "\n",
    "    def ibp_forward(self, bounds, save_relaxation=False, save_input_bounds=False):\n",
    "        lower = (bounds.lower - self.mean) / self.std\n",
    "        upper = (bounds.upper - self.mean) / self.std\n",
    "        return IntervalBounds(bounds.region, lower, upper)\n",
    "\n",
    "    @property\n",
    "    def need_relaxation(self):\n",
    "        # Not needed for ibp\n",
    "        return False\n",
    "\n",
    "    def clear_relaxation(self):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward_relaxation(self, region):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def crown_backward(self, linear_bounds, optimize):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class BoundSoftmax(BoundModule):\n",
    "    def __init__(self, model, factory, **kwargs):\n",
    "        super().__init__(model, factory, **kwargs)\n",
    "\n",
    "    def propagate_size(self, in_size):\n",
    "        return in_size\n",
    "\n",
    "    def ibp_forward(self, bounds, save_relaxation=False, save_input_bounds=False):\n",
    "        lower = F.softmax(bounds.lower, dim=-1)\n",
    "        upper = F.softmax(bounds.upper, dim=-1)\n",
    "        return IntervalBounds(bounds.region, lower, upper)\n",
    "\n",
    "    @property\n",
    "    def need_relaxation(self):\n",
    "        # Not needed for ibp\n",
    "        return False\n",
    "\n",
    "    def clear_relaxation(self):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward_relaxation(self, region):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def crown_backward(self, linear_bounds, optimize):\n",
    "        # Not needed for ibp\n",
    "        raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27153bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register all custom bound modules\n",
    "factory = BoundModelFactory()\n",
    "factory.register(nn.Sequential, BoundSequential)\n",
    "factory.register(Normalize, BoundNormalize)\n",
    "factory.register(Net, BoundNet)\n",
    "factory.register(nn.Softmax, BoundSoftmax)\n",
    "factory_model = factory.build(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12aab7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified accuracy with eps=0.01: 93.36%\n",
      "Verified accuracy with eps=0.02: 92.96%\n",
      "Verified accuracy with eps=0.03: 92.05%\n",
      "Verified accuracy with eps=0.04: 90.03%\n",
      "Verified accuracy with eps=0.05: 86.32%\n",
      "Verified accuracy with eps=0.06: 80.63%\n",
      "Verified accuracy with eps=0.07: 74.21%\n",
      "Verified accuracy with eps=0.08: 67.53%\n",
      "Verified accuracy with eps=0.09: 61.43%\n",
      "Verified accuracy with eps=0.10: 55.92%\n"
     ]
    }
   ],
   "source": [
    "# Perfom ibp analysis\n",
    "# Loop over different epsilon values\n",
    "for i in range(1, 11):\n",
    "    eps = i * 0.01\n",
    "    verified_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get input and output bounds with current epsilon\n",
    "        input_bounds = HyperRectangle.from_eps(images, eps)\n",
    "        output_bounds = factory_model.ibp(input_bounds)\n",
    "\n",
    "        # Loop through each sample in the batch to verify robustness\n",
    "        for i, true_class in enumerate(labels):\n",
    "            lower = output_bounds.lower[i]\n",
    "            upper = output_bounds.upper[i]\n",
    "\n",
    "            # Check if lower bound of true class is greater than upper bounds of all other classes\n",
    "            other_start = upper[:true_class]\n",
    "            other_end = upper[true_class+1:]\n",
    "            max_other = torch.max(torch.cat((other_start, other_end)))\n",
    "            if lower[true_class] > max_other:\n",
    "                verified_count += 1\n",
    "            total_count += 1\n",
    "\n",
    "    verified_accuracy = 100 * verified_count / total_count\n",
    "    print(f\"Verified accuracy with eps={eps:.2f}: {verified_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
